{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "sys.path.append(\"/home/psa_images/SemiF-AnnotationPipeline\")\n",
    "from utils.utils import filter_and_select_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NC_2023-02-03',\n",
       " 'NC_2023-02-06',\n",
       " 'NC_2023-02-20',\n",
       " 'NC_2023-02-22',\n",
       " 'NC_2023-03-07',\n",
       " 'NC_2023-06-12',\n",
       " 'NC_2023-07-03',\n",
       " 'NC_2023-07-10',\n",
       " 'NC_2023-07-11']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_dir = \"/mnt/research-projects/s/screberg/longterm_images/semifield-developed-images\"\n",
    "cutout_dir = \"/mnt/research-projects/s/screberg/longterm_images/semifield-cutouts/\"\n",
    "species_info_json = \"/home/psa_images/SemiF-AnnotationPipeline/data/semifield-utils/species_information/species_info.json\"\n",
    "dates_list = sorted([x.stem for x in list(Path(cutout_dir).glob(\"*\"))])\n",
    "\n",
    "start_date_str = \"2023-02-01\"\n",
    "# start_date_str = \"2023-02-03\"\n",
    "end_date_str = \"2024-02-04\"\n",
    "state_abbreviation = \"NC\"\n",
    "batch_ids = filter_and_select_dates(\n",
    "    dates_list, start_date_str, end_date_str, state_abbreviation, num_dates=\"all\"\n",
    ")\n",
    "# batch_ids = [batch_ids[0]]\n",
    "# batch_ids = ['NC_2023-07-03'] #good example\n",
    "# batch_ids = ['NC_2023-06-12']\n",
    "# batch_ids = ['MD_2023-03-16']\n",
    "batch_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[233], line 127\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mfor\u001b[39;00m json_file \u001b[39min\u001b[39;00m cutout_json_files:\n\u001b[1;32m    126\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(json_file, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 127\u001b[0m         data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m    129\u001b[0m     checker \u001b[39m=\u001b[39m BBoxChecker(data)\n\u001b[1;32m    130\u001b[0m     \u001b[39mif\u001b[39;00m checker\u001b[39m.\u001b[39mcheck_and_correct_coordinates(cutouts\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import shutil  # for file copying\n",
    "\n",
    "\n",
    "class JsonFileHandler:\n",
    "    def __init__(self, filepath, backup_dir=None, corrected_dir=None):\n",
    "        self.filepath = filepath\n",
    "        self.backup_dir = backup_dir\n",
    "        self.corrected_dir = corrected_dir\n",
    "        self.data = self._load_json()\n",
    "\n",
    "    def _load_json(self):\n",
    "        with open(self.filepath, \"r\") as file:\n",
    "            return json.load(file)\n",
    "\n",
    "    def save_corrected_json(self, data):\n",
    "        if self.backup_dir:\n",
    "            self.backup_original()\n",
    "        corrected_filepath = os.path.join(\n",
    "            self.corrected_dir, os.path.basename(self.filepath)\n",
    "        )\n",
    "        with open(corrected_filepath, \"w\") as file:\n",
    "            json.dump(data, file, indent=4)  # Using indent=4 for pretty printing\n",
    "\n",
    "    def backup_original(self):\n",
    "        backup_filepath = os.path.join(self.backup_dir, os.path.basename(self.filepath))\n",
    "        shutil.copy2(self.filepath, backup_filepath)\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data\n",
    "\n",
    "    def set_data(self, data):\n",
    "        self.data = data\n",
    "\n",
    "\n",
    "class BBoxChecker:\n",
    "    def __init__(self, data, x_range=(0, 9560), y_range=(0, 6368)):\n",
    "        # def __init__(self, data, x_range=(0, 1), y_range=(0, 1)):\n",
    "        self.data = data\n",
    "        self.x_range = x_range\n",
    "        self.y_range = y_range\n",
    "\n",
    "    def are_coordinates_normalized(self, x, y):\n",
    "        return 0 <= x <= 1 and 0 <= y <= 1\n",
    "\n",
    "    def check_and_correct_coordinates(self, cutouts=True):\n",
    "        keys_of_interest = [\"top_left\", \"top_right\", \"bottom_left\", \"bottom_right\"]\n",
    "        modified = False  # This will keep track if we've made any changes\n",
    "\n",
    "        if cutouts:\n",
    "            if \"bbox\" in data and \"local_coordinates\" in data[\"bbox\"]:\n",
    "                for key in keys_of_interest:\n",
    "                    if key in data[\"bbox\"][\"local_coordinates\"]:\n",
    "                        x, y = data[\"bbox\"][\"local_coordinates\"][key]\n",
    "                        corrected_x = float(\n",
    "                            min(max(self.x_range[0], x), self.x_range[1])\n",
    "                        )\n",
    "                        corrected_y = float(\n",
    "                            min(max(self.y_range[0], y), self.y_range[1])\n",
    "                        )\n",
    "                        if not self.are_coordinates_normalized(\n",
    "                            corrected_x, corrected_y\n",
    "                        ):\n",
    "                            print(\n",
    "                                f\"Coordinates {corrected_x}, {corrected_y} are not normalized!\"\n",
    "                            )\n",
    "                        if corrected_x != x or corrected_y != y:\n",
    "                            data[\"bbox\"][\"local_coordinates\"][key] = (\n",
    "                                corrected_x,\n",
    "                                corrected_y,\n",
    "                            )\n",
    "                            modified = True\n",
    "\n",
    "        else:\n",
    "            for bbox in self.data.get(\"bboxes\", []):\n",
    "                # print(\"bbox\", bbox)\n",
    "                if \"local_coordinates\" in bbox:\n",
    "                    for key in keys_of_interest:\n",
    "                        if key in bbox[\"local_coordinates\"]:\n",
    "                            x, y = bbox[\"local_coordinates\"][key]\n",
    "\n",
    "                            corrected_x = float(\n",
    "                                min(max(self.x_range[0], x), self.x_range[1])\n",
    "                            )\n",
    "                            corrected_y = float(\n",
    "                                min(max(self.y_range[0], y), self.y_range[1])\n",
    "                            )\n",
    "\n",
    "                            # print(corrected_x, corrected_y)\n",
    "                            if not self.are_coordinates_normalized(\n",
    "                                corrected_x, corrected_y\n",
    "                            ):\n",
    "                                print(\n",
    "                                    f\"Coordinates {corrected_x}, {corrected_y} are not normalized!\"\n",
    "                                )\n",
    "                            if corrected_x != x or corrected_y != y:\n",
    "                                # print(\"x: \", x)\n",
    "                                # print(\"y: \", y)\n",
    "                                # print(\"corrected  x: \", corrected_x)\n",
    "                                # print(\"corrected  y: \", corrected_y)\n",
    "                                bbox[\"local_coordinates\"][key] = (\n",
    "                                    corrected_x,\n",
    "                                    corrected_y,\n",
    "                                )\n",
    "                                modified = True\n",
    "\n",
    "        return modified\n",
    "\n",
    "\n",
    "# cutout_dir = \"/mnt/research-projects/s/screberg/longterm_images/semifield-cutouts/\"\n",
    "dev_dir = \"/mnt/research-projects/s/screberg/longterm_images/semifield-developed-images\"\n",
    "cutout_dir = \"/mnt/research-projects/s/screberg/longterm_images/semifield-cutouts/\"\n",
    "\n",
    "backup_dir = \"./backup_directory/\"  # Set your backup directory path here\n",
    "corrected_dir = \"./corrected_directory/\"  # Set your corrected files directory path here\n",
    "Path(backup_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(corrected_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for batch_id in batch_ids:\n",
    "    # For cutouts\n",
    "    full_cutout_dir_path = os.path.join(cutout_dir, batch_id)\n",
    "    cutout_json_files = glob.glob(os.path.join(full_cutout_dir_path, \"*.json\"))\n",
    "    for json_file in cutout_json_files:\n",
    "        with open(json_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        checker = BBoxChecker(data)\n",
    "        if checker.check_and_correct_coordinates(cutouts=True):\n",
    "            print(\n",
    "                f\"Coordinates in {json_file} (cutouts=True) for batch_id {batch_id} were not normalized and have been corrected!\"\n",
    "            )\n",
    "\n",
    "    # For developed images\n",
    "    full_dev_dir_path = os.path.join(dev_dir, batch_id, \"metadata\")\n",
    "    dev_json_files = glob.glob(os.path.join(full_dev_dir_path, \"*.json\"))\n",
    "    for json_file in dev_json_files:\n",
    "        with open(json_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        checker = BBoxChecker(data)\n",
    "        if checker.check_and_correct_coordinates(cutouts=False):\n",
    "            print(\n",
    "                f\"Coordinates in {json_file} (cutouts=False) for batch_id {batch_id} were not normalized and have been corrected!\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch: NC_2023-02-03\n",
      "Processing batch: NC_2023-02-06\n",
      "Processing batch: NC_2023-02-20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[240], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(corresponding_cutout_file):\n\u001b[1;32m     37\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(corresponding_cutout_file, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 38\u001b[0m         cutout_data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mload(f)\n\u001b[1;32m     39\u001b[0m     cutout_bbox \u001b[39m=\u001b[39m cutout_data\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbbox\u001b[39m\u001b[39m\"\u001b[39m, {})\n\u001b[1;32m     40\u001b[0m     \u001b[39m# If cutout_bbox is an empty dictionary, skip this iteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/semif/lib/python3.9/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(fp, \u001b[39m*\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_float\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_constant\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_pairs_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[39mreturn\u001b[39;00m loads(fp\u001b[39m.\u001b[39;49mread(),\n\u001b[1;32m    294\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m, object_hook\u001b[39m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[39m=\u001b[39mparse_float, parse_int\u001b[39m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[39m=\u001b[39mparse_constant, object_pairs_hook\u001b[39m=\u001b[39mobject_pairs_hook, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/anaconda3/envs/semif/lib/python3.9/codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_buffer_decode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, errors, final):\n\u001b[1;32m    315\u001b[0m     \u001b[39m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[39m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[1;32m    322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer_decode(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors, final)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "cutout_dir = \"/mnt/research-projects/s/screberg/longterm_images/semifield-cutouts/\"\n",
    "dev_dir = \"/mnt/research-projects/s/screberg/longterm_images/semifield-developed-images\"\n",
    "\n",
    "\n",
    "def get_cutout_file_path(dev_filename, bbox_id, cutout_dir_path):\n",
    "    # Modify this based on how your filenames correlate.\n",
    "    return os.path.join(cutout_dir_path, f\"{dev_filename}_{bbox_id}.json\")\n",
    "\n",
    "\n",
    "for batch_id in batch_ids:\n",
    "    print(f\"Processing batch: {batch_id}\")\n",
    "    full_dev_dir_path = os.path.join(dev_dir, batch_id, \"metadata\")\n",
    "    full_cutout_dir_path = os.path.join(cutout_dir, batch_id)\n",
    "\n",
    "    dev_json_files = glob.glob(os.path.join(full_dev_dir_path, \"*.json\"))\n",
    "    second_break = True\n",
    "    for dev_file in dev_json_files:\n",
    "        if not second_break:\n",
    "            continue\n",
    "        with open(dev_file, \"r\") as f:\n",
    "            dev_data = json.load(f)\n",
    "\n",
    "        for bbox_id, bbox in enumerate(dev_data.get(\"bboxes\", [])):\n",
    "            dev_coords = bbox.get(\"local_coordinates\", {})\n",
    "            # print(dev_coords)\n",
    "            corresponding_cutout_file = get_cutout_file_path(\n",
    "                os.path.splitext(os.path.basename(dev_file))[0],\n",
    "                bbox_id,\n",
    "                full_cutout_dir_path,\n",
    "            )\n",
    "\n",
    "            if os.path.exists(corresponding_cutout_file):\n",
    "                with open(corresponding_cutout_file, \"r\") as f:\n",
    "                    cutout_data = json.load(f)\n",
    "                cutout_bbox = cutout_data.get(\"bbox\", {})\n",
    "                # If cutout_bbox is an empty dictionary, skip this iteration\n",
    "                if not cutout_bbox:\n",
    "                    print(f\"Warning: Empty bbox data in {corresponding_cutout_file}\")\n",
    "                    second_break = False\n",
    "                    continue\n",
    "                # print(cutout_bbox)\n",
    "\n",
    "                # Check if bbox in cutout data is a list of 4 values\n",
    "                if isinstance(cutout_bbox, list) and len(cutout_bbox) == 4:\n",
    "                    y1, y2, x1, x2 = cutout_bbox\n",
    "                    expected_coords = {\n",
    "                        \"top_left\": (x1, y1),\n",
    "                        \"top_right\": (x2, y1),\n",
    "                        \"bottom_left\": (x1, y2),\n",
    "                        \"bottom_right\": (x2, y2),\n",
    "                    }\n",
    "                    # print(dev_coords)\n",
    "\n",
    "                    # Check if these expected coords match the dev_coords\n",
    "                    if dev_coords == expected_coords:\n",
    "                        cutout_data[\"bbox\"] = {\"local_coordinates\": dev_coords}\n",
    "                        print(cutout_data[\"bbox\"])\n",
    "\n",
    "                        # with open(corresponding_cutout_file, 'w') as f:\n",
    "                        # json.dump(cutout_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
